{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mp\n",
    "import sklearn\n",
    "from IPython.display import Image, HTML\n",
    "\n",
    "import laUtilities as ut\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Today, we look at a topic that has become enormously important in society: recommender systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We will\n",
    "* Define recommender systems\n",
    "* Review the challenges they pose\n",
    "* Discuss two classic methods:\n",
    "    * Collaborative Filtering\n",
    "    * Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "```{note}\n",
    "This section draws heavily on \n",
    "* These [slides](http://alex.smola.org/teaching/berkeley2012/slides/8_Recommender.pdf) by Alex Smola\n",
    "* [Matrix Factorization Techniques for Recommender Systems,](https://ieeexplore.ieee.org/document/5197422) by Yehuda Koren, Robert Bell, and Chris Volinsky, and\n",
    "* [Collaborative Filtering with Temporal Dynamics,](https://dl.acm.org/doi/10.1145/1557019.1557072) by Yehuda Koren\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What are Recommender Systems?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The concept of recommender systems emerged in the late 1990s / early 2000s as social life moved online:\n",
    "* online purchasing and commerce\n",
    "* online discussions and ratings\n",
    "* social information sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In these systems content was exploding and users were having a hard time finding things they were interested in.\n",
    "\n",
    "Users wanted recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Over time, the problem has only gotten worse:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "    \n",
    "<img src=\"figs/L20-netflix-options.png\" alt=\"Figure\" width=\"100%\">\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "    \n",
    "<img src=\"figs/L20-amazon-options.png\" alt=\"Figure\" width=\"100%\">\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "An enormous need has emerged for systems to help sort through products, services, and content items.\n",
    "\n",
    "This often goes by the term __personalization.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Some examples:\n",
    "    \n",
    "* Movie recommendation (Netflix, YouTube)\n",
    "* Related product recommendation (Amazon)\n",
    "* Web page ranking (Google)\n",
    "* Social content filtering (Facebook, Twitter)\n",
    "* Services (Airbnb, Uber, TripAdvisor)\n",
    "* News content recommendation (Apple News)\n",
    "* Priority inbox & spam filtering (Google)\n",
    "* Online dating (OK Cupid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A more formal view:\n",
    "    \n",
    "* User - requests content\n",
    "* Objects - that can be displayed\n",
    "* Context - device, location, time\n",
    "* Interface - browser, mobile\n",
    "\n",
    "<center>\n",
    "    \n",
    "<img src=\"figs/L20-recsys-abstractly.png\" alt=\"Figure\" width=\"45%\">\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Inferring Preferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Unfortunately, users generally have a hard time __explaining__ what types of content they prefer.   Some early systems worked by interviewing users to ask what they liked.  Those systems did not work very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "```{note}\n",
    "A very interesting article about the earliest personalization systems is [User Modeling via Stereotypes](https://www.cs.utexas.edu/users/ear/CogSci.pdf) by Elaine Rich, dating from 1979.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Instead, modern systems work by capturing user's opinions about __specific__ items.\n",
    "\n",
    "This can be done actively:\n",
    "* When a user is asked to **rate** a movie, product, or experience,\n",
    "\n",
    "Or it can be done passively:\n",
    "* By noting which items a user **chooses** to purchase (for example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "    \n",
    "<img src=\"figs/L20-example-data.png\" alt=\"Figure\" width=\"55%\">\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Challenges (expand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Scalability\n",
    "* Millions of objects\n",
    "* 100s of millions of users\n",
    "* Cold start\n",
    "* Changing user base\n",
    "* Changing inventory (movies, stories, goods) â€¢ Attributes\n",
    "* Imbalanced dataset\n",
    "    * User activity / item reviews are power law distributed\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "    \n",
    "<img src=\"figs/skewed-review-dist.png\" alt=\"Figure\" width=\"55%\">\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "    \n",
    "<img src=\"figs/skewed-review-dist-user.png\" alt=\"Figure\" width=\"55%\">\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A typical objective function is root mean square error (RMSE)\n",
    "\n",
    "$$ \\text{RMSE} = \\sqrt{1/|S| \\sum_{(i,u)\\in S} (\\hat{r}_{ui} - r_{ui})^2} $$\n",
    "\n",
    "where $ r_{ui} $ is the rating that user $u$ gives to item $i$, and $S$ is the set of all ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "OK, now we know the problem and the data available.   How can we address the problem?\n",
    "\n",
    "The earliest method developed is called __collaborative filtering.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The central idea of collaborative filtering is that the set of known recommendations can be considered to be a __bipartite graph.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "    \n",
    "<img src=\"figs/L20-bipartite.png\" alt=\"Figure\" width=\"35%\">\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The nodes of the bipartite graph are __users__ and __items__.   \n",
    "\n",
    "Each edge corresponds to a known rating $r_{ui}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Then recommendations are formed by traversing or processing the bipartite graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "    \n",
    "<img src=\"figs/L20-cf-basic-idea.png\" alt=\"Figure\" width=\"60%\">\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are at least two ways this graph can be used.\n",
    "\n",
    "To form a rating for item $(u, i)$: \n",
    "    \n",
    "1. Using user-user similarity:\n",
    "      * look at users that have similar item preferences to user $u$\n",
    "      * look at how those users rated item $i$\n",
    "      * Good for many users, fewer items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "    \n",
    "2. Using item-item similarity:\n",
    "      * look at other items that have been liked by similar users as item $i$\n",
    "      * look at how user $u$ rated those items\n",
    "      * Good for many items, fewer users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Example: Amazon movie reviews:\n",
    "* 1,697,533 reviews\n",
    "* 123,960 users\n",
    "* 50,052 movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Item-item CF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's look at the item-item CF approach in detail.\n",
    "\n",
    "The questions are:\n",
    "* How do we judge \"similarity\" of items?\n",
    "* How do we form a predicted rating?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here is another view of the ratings graph, this time as a matrix that includes missing entries:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    \n",
    "<img src=\"figs/L20-u-u-cf-1.png\" alt=\"Figure\" width=\"60%\">\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's say we want to predict the value of this unknown rating:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    \n",
    "<img src=\"figs/L20-u-u-cf-2.png\" alt=\"Figure\" width=\"60%\">\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We'll consider two other items, namely items 3 and 6 (for example).\n",
    "\n",
    "Note that we are only interested in items that this user has rated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    \n",
    "<img src=\"figs/L20-u-u-cf-3.png\" alt=\"Figure\" width=\"60%\">\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will discuss strategies for assessing similarity shortly. \n",
    "\n",
    "How did we choose these two items?   \n",
    "\n",
    "We used __$k$-nearest neighbors__.   Here $k$ = 2.\n",
    "\n",
    "For now, let's just say we determine the similarities as:\n",
    "\n",
    "$$ s_{13} = 0.2 $$\n",
    "\n",
    "$$ s_{16} = 0.3 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    \n",
    "<img src=\"figs/L20-u-u-cf-3.png\" alt=\"Figure\" width=\"60%\">\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "These similarity scores tell us how much weight to put on the rating of the other items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So we can form a prediction of $\\hat{r}_{15}$ as:\n",
    "    \n",
    "$$ \\hat{r}_{15} = \\frac{s_{13} \\cdot r_{35} + s_{16} \\cdot r_{65}}{s_{13} + s_{16}} = \\frac{0.2 \\cdot 2 + 0.3 \\cdot 3}{0.2 + 0.3} = 2.6 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    \n",
    "<img src=\"figs/L20-u-u-cf-4.png\" alt=\"Figure\" width=\"60%\">\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How should we assess similarity of items?\n",
    "\n",
    "A reasonable approach is to consider items similar if their ratings are __correlated.__\n",
    "\n",
    "So we can use the Pearson correlation coefficient $r$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, note that two items will not have ratings in the same positions.\n",
    "\n",
    "<center>\n",
    "    \n",
    "<img src=\"figs/L20-corr-support.png\" alt=\"Figure\" width=\"60%\">\n",
    "    \n",
    "</center>\n",
    "\n",
    "So we want to compute correlation only over the users who rated both the items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases we will need to work with binary $r_{ui}$s.  \n",
    "\n",
    "For example, purchase histories on an e-commerce site, or clicks on an ad.\n",
    "\n",
    "In this case, an appropriate replacement for Pearson $r$ is the Jaccard similarity coefficient.\n",
    "\n",
    "(See the lecture on similarity measures.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Improving CF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "One problem with the story so far arises due to __bias__.\n",
    "* Some items are significantly higher or lower rated\n",
    "* Some users rate substantially higher or lower in general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "These properties interfere with similarity assessment.  \n",
    "\n",
    "Bias correction is crucial for CF recommender systems.\n",
    "\n",
    "We need to include\n",
    "* Per-user offset\n",
    "* Per-item offset\n",
    "* Global offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence we need to form a per-item bias of:\n",
    "    \n",
    "$$ b_{ui} = \\mu + \\alpha_u + \\beta_i $$\n",
    "\n",
    "where $\\alpha_u$ is the per-user offset of user $u$ and $\\beta_i$ is the per-item offset of item $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we estimate the $\\alpha$s, the $\\beta$s, and the $\\mu$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume for a minute that we had a fully-dense matrix of ratings $R$.\n",
    "\n",
    "$R$ has items on the rows and users on the columns.\n",
    "\n",
    "Then what we want to estimate is\n",
    "\n",
    "$$\\min_{\\alpha,\\beta,\\mu} \\Vert R - \\mathbf{1}\\alpha^T + \\beta\\mathbf{1}^T + \\mu1\\Vert^2 + \\lambda(\\Vert\\alpha\\Vert^2 + \\Vert\\beta\\Vert^2) $$\n",
    "\n",
    "Here, $\\mathbf{1}$ represents appropriately sized vectors of ones, and $1$ is a matrix of ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is not a simple ordinary least squares problem, there is a strategy for solving it.\n",
    "\n",
    "Assume we hold $\\beta\\mathbf{1}^T + \\mu1$ constant.  \n",
    "\n",
    "Then the remaining problem is \n",
    "\n",
    "$$\\min_{\\alpha} \\Vert R - \\mathbf{1}\\alpha^T \\Vert^2 + \\lambda \\Vert\\alpha\\Vert^2 $$\n",
    "\n",
    "which (for each column of $R$) is a standard least squares problem (which we solve via Ridge regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sort of problem is called __jointly convex__.   \n",
    "\n",
    "The strategy for solving is:\n",
    "    \n",
    "1. Hold $\\alpha$ and $\\beta$ constant, solve for $\\mu$.\n",
    "2. Hold $\\alpha$ and $\\mu$ constant, solve for $\\beta$.\n",
    "3. Hold $\\beta$ and $\\mu$ constant, solve for $\\alpha$.\n",
    "\n",
    "Each of the three steps will reduce the overall error.   So we iterate over them until convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last issue is that the matrix $R$ is not dense - in reality we only have a small subset of its entries.\n",
    "\n",
    "We simply need to adapt the least-squares solution to only consider the entries in $R$ that we know.\n",
    "\n",
    "As a result, the actual calculation is:\n",
    "\n",
    "Step 1:\n",
    "\n",
    "$$ \\mu = \\frac{\\sum_{(u, i) \\in R} (r_{ui} - \\alpha_u - \\beta_i)}{|R|} $$\n",
    "\n",
    "Step 2: \n",
    "\n",
    "$$ \\alpha_u = \\frac{\\sum_{i \\in R(u)}(r_{ui} - \\mu - \\beta_i)}{\\lambda + |R(u)|} $$\n",
    "\n",
    "Step 3:\n",
    "    \n",
    "$$ \\beta_i = \\frac{\\sum_{u \\in R(i)}(r_{ui} - \\mu - \\alpha_u)}{\\lambda + |R(i)|} $$\n",
    "\n",
    "Step 4: If not converged, go to Step 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the biases learned, we can do a better job of estimating correlation:\n",
    "\n",
    "$$ \\hat{\\rho}_{ij} = \\frac{\\sum_{u\\in U(i,j)}(r_{ui} - b_{ui})(r_{uj}-b_{uj})} \n",
    "{\\sqrt{\\sum_{u\\in U(i,j)}(r_{ui} - b_{ui})^2\\sum_{u\\in U(i,j)}(r_{uj}-b_{uj})^2}} $$\n",
    "\n",
    "where \n",
    "* $b_{ui} = \\mu + \\alpha_u + \\beta_i$, and\n",
    "* $U(i,j)$ are the users who have rated both $i$ and $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And using biases we can also do a better job of estimating ratings:\n",
    "\n",
    "$$ \\hat{r}_{ui} = b_{ui} + \\frac{\\sum_{j \\in n_k(i, u)} s_{ij}(r_{uj} - b_{uj})}{\\sum_{j \\in n_k(i, u)} s_{ij}} $$\n",
    "\n",
    "where \n",
    "* $b_{ui} = \\mu + \\alpha_u + \\beta_i$, and\n",
    "* $n_k(i, u)$ are the $k$ nearest neighbors to $i$ that were rated by user $u$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Assessing CF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This completes the high level view of CF.\n",
    "\n",
    "Working with user-user similarities is analogous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Strengths:\n",
    "* Essentially no training.\n",
    "    * The reliance on $k$-nearest neighbors helps in this respect.\n",
    "* Easy to update with new users, items, and ratings\n",
    "* Can be explained to user: \n",
    "    * \"We recommend _Minority Report_ because you liked _Blade Runner_ and _Total Recall._\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Weaknesses:\n",
    "* Accuracy can be a problem\n",
    "* Scalability can be a problem (think $k$-NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that standard CF forces us to consider similarity among items, __or__ among users, but does not take into account __both.__\n",
    "\n",
    "Can we use both kinds of similarity simultaneously?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can't use both the rows and columns of the ratings matrix $R$ at the same time -- the user and item vectors live in different vector spaces.\n",
    "\n",
    "What we could try to do is find a __single__ vector space in which we represent __both__ users __and__ items, along with a similarity function, such that:\n",
    "* users who have similar item ratings are similar in the vector space\n",
    "* items who have similar user ratings are similar in the vector space\n",
    "* when a given user highly rates a given item, that user and item are similar in the vector space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "    \n",
    "<img src=\"figs/L10-Movie-Latent-Space.png\" alt=\"Figure\" width=\"60%\">\n",
    "    \n",
    "</center>\n",
    "\n",
    "Koren et al, IEEE Computer, 2009 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We saw this idea previously, in an SVD lecture.\n",
    "\n",
    "This new vector space is called a __latent__ space,\n",
    "\n",
    "and the user and item representations are called __latent vectors.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now, however, we are working with a matrix which is only __partially observed.__\n",
    "\n",
    "That is, we only know __some__ of the entries in the ratings matrix.\n",
    "\n",
    "Nonetheless, we can imagine a situation like this:\n",
    "    \n",
    "<center>\n",
    "    \n",
    "<img src=\"figs/L20-mf-1.png\" alt=\"Figure\" width=\"60%\">\n",
    "    \n",
    "</center>\n",
    "\n",
    "Now we want the product of the two matrices on the right to be as close as possible __to the known values__ of the ratings matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What this setup implies is that our similarity function is the __inner product.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Which means that to predict an unknown rating, we take the __inner product of latent vectors:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    \n",
    "<img src=\"figs/L20-mf-2.png\" alt=\"Figure\" width=\"60%\">\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now $(-2 \\cdot -0.5)+(0.3 \\cdot 0.6)+(2.5 \\cdot 0.5) = 2.43$, so:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    \n",
    "<img src=\"figs/L20-mf-3.png\" alt=\"Figure\" width=\"60%\">\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Solving Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice that in this case we've decided that the factorization should be rank 3.\n",
    "\n",
    "So we want something like an SVD.\n",
    "\n",
    "(Recall that SVD gives us the most-accurate-possible low-rank factorization of a matrix)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, we can't use the SVD algorithm directly, because we don't know all the entries in $R$. \n",
    "\n",
    "(Indeed, the unseen entries in $R$ as exactly what we want to predict.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "    \n",
    "<img src=\"figs/L20-mf-1.png\" alt=\"Figure\" width=\"60%\">\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what we want to solve: \n",
    "    \n",
    "$$ \\min_{U,V} \\Vert R - UV^T\\Vert^2 + \\lambda(\\Vert U\\Vert^2 + \\Vert V\\Vert^2) $$\n",
    "\n",
    "where $R$ is $m\\times n$, $U$ is the $m\\times k$ items matrix and $V$ is the $n\\times k$ users matrix.\n",
    "\n",
    "Note that as usual, we add $\\ell_2$ penalization to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, this problem is __jointly convex.__   \n",
    "\n",
    "In particular, it we hold either $U$ or $V$ constant, then the result is a simple ridge regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So one commonly used algorithm for this problem is called __alternating least squares:__\n",
    "    \n",
    "1. Hold $U$ constant, and solve for $V$\n",
    "2. Hold $V$ constant, and solve for $U$\n",
    "3. If not converged, go to Step 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
