
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Low Rank Approximation and the SVD &#8212; Computational Tools for Data Science</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Dimensionality Reduction and PCA – SVD II" href="11-Dimensionality-Reduction-SVD-II.html" />
    <link rel="prev" title="Naive Bayes and Support Vector Machines" href="16-Classification-III-NB-SVM.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/L09-MultivariateNormal.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Computational Tools for Data Science</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="landing-page.html">
   Preface
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Preliminaries
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01-Intro-to-Python.html">
   Introduction to Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02A-Git-Jupyter.html">
   Essential Tools: Git and Jupyter
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02B-Pandas.html">
   Essential Tools: Pandas
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04-Linear-Algebra-Refresher.html">
   Linear Algebra Refresher
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03-Probability-and-Statistics-Refresher.html">
   Probability and Statistics Refresher
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Clustering
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="05-Distances-Timeseries.html">
   Distances and Timeseries
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="06-Clustering-I-kmeans.html">
   <span class="math notranslate nohighlight">
    \(k\)
   </span>
   -means
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="07-Clustering-II-in-practice.html">
   Clustering In Practice
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="08-Clustering-III-hierarchical.html">
   Hierarchical Clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="09-Clustering-IV-GMM-EM.html">
   Gaussian Mixture Models
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Classification
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="13-Learning-From-Data.html">
   Learning From Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="14-Classification-I-Decision-Trees.html">
   Decision Trees
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="15-Classification-II-kNN.html">
   <span class="math notranslate nohighlight">
    \(k\)
   </span>
   -Nearest Neighbors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="16-Classification-III-NB-SVM.html">
   Naive Bayes and Support Vector Machines
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Dimensionality Reduction
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Low Rank Approximation and the SVD
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="11-Dimensionality-Reduction-SVD-II.html">
   Dimensionality Reduction and PCA – SVD II
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Regression
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="17-Regression-I-Linear.html">
   Linear Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="18-Regression-II-Logistic.html">
   Logistic Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="19-Regression-III-More-Linear.html">
   Regularization
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Selected Topics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="20-Recommender-Systems.html">
   Recommender Systems
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="21-Networks-I.html">
   Introduction to Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="22-Networks-II-Centrality-Clustering.html">
   Network Centrality and Clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="23-Gradient-Descent.html">
   Gradient Descent
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/10-Low-Rank-and-SVD.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/mcrovella/CS506-Computational-Tools-for-Data-Science"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/mcrovella/CS506-Computational-Tools-for-Data-Science/master?urlpath=tree/10-Low-Rank-and-SVD.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#models-are-simplifications">
   Models are simplifications
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-matrices">
   Data Matrices
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#matrix-rank">
   Matrix Rank
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#low-effective-rank">
   Low Effective Rank
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#finding-rank-k-approximations">
   Finding Rank-
   <span class="math notranslate nohighlight">
    \(k\)
   </span>
   Approximations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   Low Effective Rank
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#empirical-evidence">
   Empirical Evidence
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#low-effective-rank-is-common">
   Low Effective Rank is Common
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#interpretations-of-low-effective-rank">
   Interpretations of Low Effective Rank
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#low-rank-implies-common-patterns">
     Low Rank Implies Common Patterns
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#low-rank-defines-latent-factors">
     Low Rank Defines Latent Factors
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Low Rank Approximation and the SVD</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#models-are-simplifications">
   Models are simplifications
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-matrices">
   Data Matrices
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#matrix-rank">
   Matrix Rank
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#low-effective-rank">
   Low Effective Rank
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#finding-rank-k-approximations">
   Finding Rank-
   <span class="math notranslate nohighlight">
    \(k\)
   </span>
   Approximations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   Low Effective Rank
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#empirical-evidence">
   Empirical Evidence
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#low-effective-rank-is-common">
   Low Effective Rank is Common
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#interpretations-of-low-effective-rank">
   Interpretations of Low Effective Rank
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#low-rank-implies-common-patterns">
     Low Rank Implies Common Patterns
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#low-rank-defines-latent-factors">
     Low Rank Defines Latent Factors
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="cell tag_hide-cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mp</span>
<span class="kn">import</span> <span class="nn">sklearn</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="low-rank-approximation-and-the-svd">
<h1>Low Rank Approximation and the SVD<a class="headerlink" href="#low-rank-approximation-and-the-svd" title="Permalink to this headline">¶</a></h1>
<p>Today, we move on.</p>
<p>However, let’s look back and try to put the modeling we’ve done into a larger context.</p>
<div class="section" id="models-are-simplifications">
<h2>Models are simplifications<a class="headerlink" href="#models-are-simplifications" title="Permalink to this headline">¶</a></h2>
<p>One way of thinking about modeling or clustering is that we are building a <strong>simplification</strong> of the data.</p>
<p>That is, a model of the data that is simpler than the data.</p>
<p>In particular, instead of thinking of the data as thousands or millions of individual data points, we think of it in terms of a small number of clusters, or a parametric distribution, etc, etc.</p>
<p>From this simpler description, we hope to gain <strong>insight.</strong></p>
<p>There is an interesting question here:  <strong>why</strong> does this process often lead to insight?</p>
<p>That is, why does it happen so often that a large dataset can be described in terms of a much simpler model?</p>
<p>I don’t know.</p>
<center>
<a class="reference internal image-reference" href="_images/L10-William-of-Ockham.png"><img alt="Figure" src="_images/L10-William-of-Ockham.png" style="width: 40%;" /></a>
</center><p>By self-created (Moscarlop) - Own work, <a href="http://creativecommons.org/licenses/by-sa/3.0" title="Creative Commons Attribution-Share Alike 3.0">CC BY-SA 3.0</a>, <a href="https://commons.wikimedia.org/w/index.php?curid=5523066">Link</a></p>
<p>However, I think that William of Ockham (c. 1300 AD) was on the right track.</p>
<p>He said:</p>
<blockquote>
<div><p>Non sunt multiplicanda entia sine necessitate</p>
</div></blockquote>
<p>or, in other words:</p>
<blockquote>
<div><p>Entities must not be multiplied beyond necessity.</p>
</div></blockquote>
<p>by which he meant:</p>
<blockquote>
<div><p>Among competing hypotheses, the one with the fewest assumptions should be selected.</p>
</div></blockquote>
<p>Which has come to be known as “Occam’s razor.”</p>
<p>William was saying that it is more common for a set of observations to be determined by a simple process than a complex process.</p>
<p>In other words, the world is full of simple (but often hidden) patterns.</p>
<p>From which one can justify the observation that “modeling works suprisingly often.”</p>
</div>
<div class="section" id="data-matrices">
<h2>Data Matrices<a class="headerlink" href="#data-matrices" title="Permalink to this headline">¶</a></h2>
<p>Now we’ll consider a (seemingly) very different approximation of data, applicable to data when it is in matrix form.</p>
<div class="math notranslate nohighlight">
\[\begin{split}{\mbox{$m$ data objects}}\left\{\begin{array}{c}\;\\\;\\\;\\\;\\\;\end{array}\right.\;\;\overbrace{\left[\begin{array}{ccccc}
\begin{array}{c}a_{11}\\\vdots\\a_{i1}\\\vdots\\a_{m1}\end{array}&amp;
\begin{array}{c}\dots\\\ddots\\\dots\\\ddots\\\dots\end{array}&amp;
\begin{array}{c}a_{1j}\\\vdots\\a_{ij}\\\vdots\\a_{mj}\end{array}&amp;
\begin{array}{c}\dots\\\ddots\\\dots\\\ddots\\\dots\end{array}&amp;
\begin{array}{c}a_{1n}\\\vdots\\a_{in}\\\vdots\\a_{mn}\end{array}
\end{array}\right]}^{\mbox{$n$ features}}\end{split}\]</div>
<table>
<tr><th>Data Type</th><th>Rows</th><th>Columns</th><th>Elements</th></tr>
<tr><td>Network Traffic<td>Sources</td><td>Destinations</td><td>Number of Bytes</td></tr>
<tr><td>Social Media</td><td>Users</td><td>time bins</td><td>Number of Posts/Tweets/Likes</td></tr>
<tr><td>Web Browsing</td><td>Users</td><td>Content Categories</td><td>Visit Counts/Bytes Downloaded</td></tr>
<tr><td>Web Browsing</td><td>Users</td><td>time bins</td><td>Visit Counts/Bytes Downloaded</td></tr>
</table></div>
<div class="section" id="matrix-rank">
<h2>Matrix Rank<a class="headerlink" href="#matrix-rank" title="Permalink to this headline">¶</a></h2>
<p>Let’s briefly review some definitions.</p>
<p>We’ll consider an <span class="math notranslate nohighlight">\(m\times n\)</span> real matrix <span class="math notranslate nohighlight">\(A\)</span>.</p>
<p>The <strong>rank</strong> of <span class="math notranslate nohighlight">\(A\)</span> is the <strong>dimension of its column space.</strong></p>
<p>The dimension of a space is the smallest number of (linearly independent) vectors needed to span the space.</p>
<p>So the dimension of the column space of <span class="math notranslate nohighlight">\(A\)</span> is the <strong>smallest number of vectors that suffice to construct the columns of <span class="math notranslate nohighlight">\(A\)</span>.</strong></p>
<p>Then the rank of <span class="math notranslate nohighlight">\(A\)</span> is the size of the smallest set <span class="math notranslate nohighlight">\(\{\mathbf{u}_1, \mathbf{u}_2, \dots, \mathbf{u}_p\}\)</span> such that every column <span class="math notranslate nohighlight">\(\mathbf{a}_i\)</span> can be expressed as:</p>
<div class="math notranslate nohighlight">
\[\mathbf{a}_i = c_{i1}\mathbf{u}_1 + c_{i2}\mathbf{u}_2 + \dots + c_{ip}\mathbf{u}_p\;\;\;\;i=1,\dots,n.\]</div>
<p>The largest value that a matrix rank can take is <span class="math notranslate nohighlight">\(\min(m,n)\)</span>.</p>
<p>However it can happen that the rank of a matrix is <strong>less</strong> than <span class="math notranslate nohighlight">\(\min(m,n)\)</span>.</p>
<p>Now to store a matrix <span class="math notranslate nohighlight">\(A \in \mathbb{R}^{m\times n}\)</span> we need to store <span class="math notranslate nohighlight">\(m n\)</span> values.</p>
<p>However, if <span class="math notranslate nohighlight">\(A\)</span> has rank <span class="math notranslate nohighlight">\(k\)</span>, it can be factored as <span class="math notranslate nohighlight">\(A = UV\)</span>,</p>
<p>where <span class="math notranslate nohighlight">\(U \in \mathbb{R}^{m\times k}\)</span> and <span class="math notranslate nohighlight">\(V \in \mathbb{R}^{k \times n}\)</span>.</p>
<p>This only requires <span class="math notranslate nohighlight">\(k(m+n)\)</span> values, which could be much smaller than <span class="math notranslate nohighlight">\(mn\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split} \mbox{$m$ data objects}\left\{\begin{array}{c}\;\\\;\\\;\\\;\\\;\end{array}\right.\;\;\overbrace{\left[\begin{array}{ccccc}
\begin{array}{c}a_{11}\\\vdots\\a_{i1}\\\vdots\\a_{m1}\end{array}&amp;
\begin{array}{c}\dots\\\ddots\\\dots\\\ddots\\\dots\end{array}&amp;
\begin{array}{c}a_{1j}\\\vdots\\a_{ij}\\\vdots\\a_{mj}\end{array}&amp;
\begin{array}{c}\dots\\\ddots\\\dots\\\ddots\\\dots\end{array}&amp;
\begin{array}{c}a_{1n}\\\vdots\\a_{in}\\\vdots\\a_{mn}\end{array}
\end{array}\right]}^\mbox{$n$ features} =
\overbrace{\left[\begin{array}{cc}\vdots&amp;\vdots\\\vdots&amp;\vdots\\\mathbf{u}_1&amp;\mathbf{u}_k\\\vdots&amp;\vdots\\\vdots&amp;\vdots\end{array}\right]}^{\large k}
\times
\left[\begin{array}{ccccc}\dots&amp;\dots&amp;\mathbf{v}_1&amp;\dots&amp;\dots\\\dots&amp;\dots&amp;\mathbf{v}_k&amp;\dots&amp;\dots\end{array}\right]\end{split}\]</div>
</div>
<div class="section" id="low-effective-rank">
<h2>Low Effective Rank<a class="headerlink" href="#low-effective-rank" title="Permalink to this headline">¶</a></h2>
<p>In many situations we may wish to <strong>approximate</strong> a data matrix <span class="math notranslate nohighlight">\(A\)</span> with a low-rank matrix <span class="math notranslate nohighlight">\(A^{(k)}.\)</span></p>
<p>To talk about when one matrix “approximates” another, we need a norm for matrices.</p>
<p>We will use the <strong>Frobenius norm</strong> which is just the usual <span class="math notranslate nohighlight">\(\ell_2\)</span> norm, treating the matrix as a vector.</p>
<p>The definition of the Frobenius norm of <span class="math notranslate nohighlight">\(A\)</span>, denoted <span class="math notranslate nohighlight">\(\Vert A\Vert_F\)</span>, is:</p>
<div class="math notranslate nohighlight">
\[\Vert A\Vert_F = \sqrt{\sum a_{ij}^2}.\]</div>
<p>To quantify when one matrix is “close” to another, we use distance in Euclidean space:</p>
<div class="math notranslate nohighlight">
\[\mbox{dist}(A,B) = \Vert A-B\Vert_F.\]</div>
<p>(where the Euclidean space is the <span class="math notranslate nohighlight">\(mn\)</span>-dimensional space of <span class="math notranslate nohighlight">\(m\times n\)</span> matrices.)</p>
<p>Now we can define the <strong>rank-<span class="math notranslate nohighlight">\(k\)</span> approximation</strong> to <span class="math notranslate nohighlight">\(A\)</span>:</p>
<p>When <span class="math notranslate nohighlight">\(k &lt; \operatorname{Rank} A\)</span>, the rank-<span class="math notranslate nohighlight">\(k\)</span> approximation to <span class="math notranslate nohighlight">\(A\)</span> is the closest rank-<span class="math notranslate nohighlight">\(k\)</span> matrix to <span class="math notranslate nohighlight">\(A\)</span>, i.e.,</p>
<div class="math notranslate nohighlight">
\[A^{(k)} =\arg \min_{\{B\;|\;\operatorname{Rank} B = k\}} \Vert A-B\Vert_F.\]</div>
<p>This can also be considered the best rank-<span class="math notranslate nohighlight">\(k\)</span> approximation to <span class="math notranslate nohighlight">\(A\)</span> in a least-squares sense.</p>
<p>Let’s say we have <span class="math notranslate nohighlight">\(A^{(k)}\)</span>, a rank-<span class="math notranslate nohighlight">\(k\)</span> approximation to <span class="math notranslate nohighlight">\(A\)</span>.</p>
<p>By definition, there is a set <span class="math notranslate nohighlight">\(\mathcal{U}\)</span> consisting of <span class="math notranslate nohighlight">\(k\)</span> vectors such that each column of <span class="math notranslate nohighlight">\(A^{(k)}\)</span> can be expressed as a linear combination of vectors in <span class="math notranslate nohighlight">\(\mathcal{U}\)</span>.</p>
<p>Let us  call the matrix formed by those vectors <span class="math notranslate nohighlight">\(U\)</span>.</p>
<p>So</p>
<div class="math notranslate nohighlight">
\[A^{(k)} = UV^T\]</div>
<p>for some set of coefficients <span class="math notranslate nohighlight">\(V^T\)</span> that describe the linear combinations of <span class="math notranslate nohighlight">\(U\)</span> that yield the columns of <span class="math notranslate nohighlight">\(A^{(k)}\)</span>.</p>
<p>So <span class="math notranslate nohighlight">\(U\)</span> is <span class="math notranslate nohighlight">\(m\times k\)</span> and <span class="math notranslate nohighlight">\(V\)</span> is <span class="math notranslate nohighlight">\(n\times k\)</span>.</p>
<p>If we approximate <span class="math notranslate nohighlight">\(A\)</span> by <span class="math notranslate nohighlight">\(A^{(k)}\)</span>, then the error we incur is:</p>
<div class="math notranslate nohighlight">
\[\Vert A-A^{(k)}\Vert_F.\]</div>
<p>Hence, a rank-<span class="math notranslate nohighlight">\(k\)</span> approximation <span class="math notranslate nohighlight">\(A^{(k)}\)</span> is valuable if</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\Vert A-A^{(k)}\Vert_F\)</span> is small compared to <span class="math notranslate nohighlight">\(\Vert A\Vert_F\)</span>, and</p></li>
<li><p><span class="math notranslate nohighlight">\(k\)</span> is small compared to <span class="math notranslate nohighlight">\(m\)</span> and <span class="math notranslate nohighlight">\(n\)</span>.</p></li>
</ul>
<p>In that case we have achieved a simplification of the data without a great loss in accuracy.</p>
</div>
<div class="section" id="finding-rank-k-approximations">
<h2>Finding Rank-<span class="math notranslate nohighlight">\(k\)</span> Approximations<a class="headerlink" href="#finding-rank-k-approximations" title="Permalink to this headline">¶</a></h2>
<p>There is a celebrated method for finding the best rank-<span class="math notranslate nohighlight">\(k\)</span> approximation to any matrix: the <strong>Singular Value Decomposition (SVD).</strong></p>
<blockquote>
<div><p>SVD is “the Rolls-Royce and the Swiss Army Knife of Numerical Linear Algebra.”</p>
</div></blockquote>
<p>Dianne O’Leary, MMDS ’06</p>
<p>The singular value decomposition of a rank-<span class="math notranslate nohighlight">\(r\)</span> matrix <span class="math notranslate nohighlight">\(A\)</span> has the form:</p>
<div class="math notranslate nohighlight">
\[A = U\Sigma V^T\]</div>
<p>where</p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(U\)</span> is <span class="math notranslate nohighlight">\(m\times r\)</span></p></li>
<li><p>The columns of <span class="math notranslate nohighlight">\(U\)</span> are mutually orthogonal and unit length, ie., <span class="math notranslate nohighlight">\(U^TU = I\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(V\)</span> is <span class="math notranslate nohighlight">\(n\times r\)</span>.</p></li>
<li><p>The columns of <span class="math notranslate nohighlight">\(V\)</span> are mutually orthogonal and unit length, ie., <span class="math notranslate nohighlight">\(V^TV = I\)</span>.</p></li>
<li><p>The matrix <span class="math notranslate nohighlight">\(\Sigma\)</span> is an <span class="math notranslate nohighlight">\(r\times r\)</span> diagonal matrix, whose diagonal values are <span class="math notranslate nohighlight">\(\sigma_1 \geq \sigma_2 \geq \dots \geq \sigma_r &gt; 0\)</span>.</p></li>
</ol>
<div class="math notranslate nohighlight">
\[\begin{split} \left[\begin{array}{cccc}\begin{array}{c}\vdots\\\vdots\\{\bf a_1}\\\vdots\\\vdots\end{array}&amp;\begin{array}{c}\vdots\\\vdots\\{\bf a_2}\\\vdots\\\vdots\end{array}&amp;\dots&amp;\begin{array}{c}\vdots\\\vdots\\{\bf a_n}\\\vdots\\\vdots\end{array}\\\end{array}\right] =
\overbrace{\left[\begin{array}{cc}\vdots&amp;\vdots\\\vdots&amp;\vdots\\\mathbf{u}_1&amp;\mathbf{u}_r\\\vdots&amp;\vdots\\\vdots&amp;\vdots\end{array}\right]}^{\large r}
\times
\left[\begin{array}{cc}\sigma_1&amp;~\\~&amp;\sigma_r\\\end{array}\right]
\times
\left[\begin{array}{ccccc}\dots&amp;\dots&amp;\mathbf{v}_1&amp;\dots&amp;\dots\\\dots&amp;\dots&amp;\mathbf{v}_r&amp;\dots&amp;\dots\end{array}\right]\end{split}\]</div>
<p>Npw, the SVD is <em>incredibly useful</em> for finding matrix approximations.</p>
<p>In particular, for an <span class="math notranslate nohighlight">\(m\times n\)</span> matrix <span class="math notranslate nohighlight">\(A\)</span>, the SVD does two things:</p>
<ol class="simple">
<li><p>It gives the best rank-<span class="math notranslate nohighlight">\(k\)</span> approximation to <span class="math notranslate nohighlight">\(A\)</span> for <strong>every</strong> <span class="math notranslate nohighlight">\(k\)</span> up to the rank of <span class="math notranslate nohighlight">\(A\)</span>.</p></li>
<li><p>It gives the <strong>distance</strong> of the best approximation <span class="math notranslate nohighlight">\(A^{(k)}\)</span> from <span class="math notranslate nohighlight">\(A\)</span> for each <span class="math notranslate nohighlight">\(k\)</span>.</p></li>
</ol>
<p>In terms of the singular value decomposition,</p>
<p>The best rank-<span class="math notranslate nohighlight">\(k\)</span> approximation to <span class="math notranslate nohighlight">\(A\)</span> is formed by taking</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(U' = \)</span> the <span class="math notranslate nohighlight">\(k\)</span> leftmost columns of <span class="math notranslate nohighlight">\(U\)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\(\Sigma' = \)</span> the <span class="math notranslate nohighlight">\(k\times k\)</span> upper left submatrix of <span class="math notranslate nohighlight">\(\Sigma\)</span>, and</p></li>
<li><p><span class="math notranslate nohighlight">\(V'= \)</span> the <span class="math notranslate nohighlight">\(k\)</span> leftmost columns of <span class="math notranslate nohighlight">\(V\)</span>, and constructing</p></li>
</ul>
<div class="math notranslate nohighlight">
\[ A^{(k)} = U'\Sigma'(V')^T.\]</div>
<p>Furthermore, the distance (in Frobenius norm) of the best rank-<span class="math notranslate nohighlight">\(k\)</span> approximation <span class="math notranslate nohighlight">\(A^{(k)}\)</span> from <span class="math notranslate nohighlight">\(A\)</span> is equal to <span class="math notranslate nohighlight">\(\sqrt{\sum_{i=k+1}^r\sigma^2_i}\)</span>.</p>
<p>That is, if you construct <span class="math notranslate nohighlight">\(A^{(k)}\)</span> as shown above, then:</p>
<div class="math notranslate nohighlight">
\[\Vert A-A^{(k)}\Vert_F^2 = \sum_{i=k+1}^r\sigma^2_i\]</div>
</div>
<div class="section" id="id1">
<h2>Low Effective Rank<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>Almost any data matrix <span class="math notranslate nohighlight">\(A\)</span> that one encounters will usually be <strong>full rank</strong>,</p>
<p>meaning that <span class="math notranslate nohighlight">\(\operatorname{Rank} A = \min(m, n)\)</span>.</p>
<p>However, it is often the case that data matrices have <strong>low effective rank.</strong></p>
<p>By this we mean that one can usefully approximate <span class="math notranslate nohighlight">\(A\)</span> by some <span class="math notranslate nohighlight">\(A^{(k)}\)</span> for which <span class="math notranslate nohighlight">\(k \ll \min(m,n)\)</span>.</p>
<p>For any data matrix, we can judge when this is the case by looking at its singular values, because the singular values tell us the distance to the nearest rank-<span class="math notranslate nohighlight">\(k\)</span> matrix.</p>
</div>
<div class="section" id="empirical-evidence">
<h2>Empirical Evidence<a class="headerlink" href="#empirical-evidence" title="Permalink to this headline">¶</a></h2>
<p>Let’s see how this theory can be used in practice, and investigate some real data.</p>
<p>We’ll look at data traffic on the Abilene network:</p>
<img alt="_images/L10-Abilene-map.png" src="_images/L10-Abilene-map.png" />
<p>Source: Internet2, circa 2005</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;data/net-traffic/AbileneFlows/odnames&#39;</span><span class="p">,</span><span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">odnames</span> <span class="o">=</span> <span class="p">[</span><span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">]</span>
<span class="n">dates</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">date_range</span><span class="p">(</span><span class="s1">&#39;9/1/2003&#39;</span><span class="p">,</span> <span class="n">freq</span> <span class="o">=</span> <span class="s1">&#39;10min&#39;</span><span class="p">,</span> <span class="n">periods</span> <span class="o">=</span> <span class="mi">1008</span><span class="p">)</span>
<span class="n">Atraf</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="s1">&#39;data/net-traffic/AbileneFlows/X&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;  &#39;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="n">odnames</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s1">&#39;python&#39;</span><span class="p">)</span>
<span class="n">Atraf</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">dates</span>
<span class="n">Atraf</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ATLA-ATLA</th>
      <th>ATLA-CHIN</th>
      <th>ATLA-DNVR</th>
      <th>ATLA-HSTN</th>
      <th>ATLA-IPLS</th>
      <th>ATLA-KSCY</th>
      <th>ATLA-LOSA</th>
      <th>ATLA-NYCM</th>
      <th>ATLA-SNVA</th>
      <th>ATLA-STTL</th>
      <th>...</th>
      <th>WASH-CHIN</th>
      <th>WASH-DNVR</th>
      <th>WASH-HSTN</th>
      <th>WASH-IPLS</th>
      <th>WASH-KSCY</th>
      <th>WASH-LOSA</th>
      <th>WASH-NYCM</th>
      <th>WASH-SNVA</th>
      <th>WASH-STTL</th>
      <th>WASH-WASH</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2003-09-01 00:00:00</th>
      <td>8466132.0</td>
      <td>29346537.0</td>
      <td>15792104.0</td>
      <td>3646187.0</td>
      <td>21756443.0</td>
      <td>10792818.0</td>
      <td>14220940.0</td>
      <td>25014340.0</td>
      <td>13677284.0</td>
      <td>10591345.0</td>
      <td>...</td>
      <td>53296727.0</td>
      <td>18724766.0</td>
      <td>12238893.0</td>
      <td>52782009.0</td>
      <td>12836459.0</td>
      <td>31460190.0</td>
      <td>105796930.0</td>
      <td>13756184.0</td>
      <td>13582945.0</td>
      <td>120384980.0</td>
    </tr>
    <tr>
      <th>2003-09-01 00:10:00</th>
      <td>20524567.0</td>
      <td>28726106.0</td>
      <td>8030109.0</td>
      <td>4175817.0</td>
      <td>24497174.0</td>
      <td>8623734.0</td>
      <td>15695839.0</td>
      <td>36788680.0</td>
      <td>5607086.0</td>
      <td>10714795.0</td>
      <td>...</td>
      <td>68413060.0</td>
      <td>28522606.0</td>
      <td>11377094.0</td>
      <td>60006620.0</td>
      <td>12556471.0</td>
      <td>32450393.0</td>
      <td>70665497.0</td>
      <td>13968786.0</td>
      <td>16144471.0</td>
      <td>135679630.0</td>
    </tr>
    <tr>
      <th>2003-09-01 00:20:00</th>
      <td>12864863.0</td>
      <td>27630217.0</td>
      <td>7417228.0</td>
      <td>5337471.0</td>
      <td>23254392.0</td>
      <td>7882377.0</td>
      <td>16176022.0</td>
      <td>31682355.0</td>
      <td>6354657.0</td>
      <td>12205515.0</td>
      <td>...</td>
      <td>67969461.0</td>
      <td>37073856.0</td>
      <td>15680615.0</td>
      <td>61484233.0</td>
      <td>16318506.0</td>
      <td>33768245.0</td>
      <td>71577084.0</td>
      <td>13938533.0</td>
      <td>14959708.0</td>
      <td>126175780.0</td>
    </tr>
    <tr>
      <th>2003-09-01 00:30:00</th>
      <td>10856263.0</td>
      <td>32243146.0</td>
      <td>7136130.0</td>
      <td>3695059.0</td>
      <td>28747761.0</td>
      <td>9102603.0</td>
      <td>16200072.0</td>
      <td>27472465.0</td>
      <td>9402609.0</td>
      <td>10934084.0</td>
      <td>...</td>
      <td>66616097.0</td>
      <td>43019246.0</td>
      <td>12726958.0</td>
      <td>64027333.0</td>
      <td>16394673.0</td>
      <td>33440318.0</td>
      <td>79682647.0</td>
      <td>16212806.0</td>
      <td>16425845.0</td>
      <td>112891500.0</td>
    </tr>
    <tr>
      <th>2003-09-01 00:40:00</th>
      <td>10068533.0</td>
      <td>30164311.0</td>
      <td>8061482.0</td>
      <td>2922271.0</td>
      <td>35642229.0</td>
      <td>9104036.0</td>
      <td>12279530.0</td>
      <td>29171205.0</td>
      <td>7624924.0</td>
      <td>11327807.0</td>
      <td>...</td>
      <td>66797282.0</td>
      <td>40408580.0</td>
      <td>11733121.0</td>
      <td>54541962.0</td>
      <td>16769259.0</td>
      <td>33927515.0</td>
      <td>81480788.0</td>
      <td>16757707.0</td>
      <td>15158825.0</td>
      <td>123140310.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2003-09-07 23:10:00</th>
      <td>8849096.0</td>
      <td>33461807.0</td>
      <td>5866138.0</td>
      <td>3786793.0</td>
      <td>19097140.0</td>
      <td>10561532.0</td>
      <td>26092040.0</td>
      <td>28640962.0</td>
      <td>8343867.0</td>
      <td>8820650.0</td>
      <td>...</td>
      <td>65925313.0</td>
      <td>21751316.0</td>
      <td>11058944.0</td>
      <td>58591021.0</td>
      <td>17137907.0</td>
      <td>24297674.0</td>
      <td>83293655.0</td>
      <td>17329425.0</td>
      <td>20865535.0</td>
      <td>123125390.0</td>
    </tr>
    <tr>
      <th>2003-09-07 23:20:00</th>
      <td>9776675.0</td>
      <td>31474607.0</td>
      <td>5874654.0</td>
      <td>11277465.0</td>
      <td>14314837.0</td>
      <td>9106198.0</td>
      <td>26412752.0</td>
      <td>26168288.0</td>
      <td>8638782.0</td>
      <td>9193717.0</td>
      <td>...</td>
      <td>70075490.0</td>
      <td>29126443.0</td>
      <td>12667321.0</td>
      <td>54571764.0</td>
      <td>15383038.0</td>
      <td>25238842.0</td>
      <td>70015955.0</td>
      <td>16526455.0</td>
      <td>16881206.0</td>
      <td>142106800.0</td>
    </tr>
    <tr>
      <th>2003-09-07 23:30:00</th>
      <td>9144621.0</td>
      <td>32117262.0</td>
      <td>5762691.0</td>
      <td>7154577.0</td>
      <td>17771350.0</td>
      <td>10149256.0</td>
      <td>29501669.0</td>
      <td>25998158.0</td>
      <td>11343171.0</td>
      <td>9423042.0</td>
      <td>...</td>
      <td>68544458.0</td>
      <td>27817836.0</td>
      <td>15892668.0</td>
      <td>50326213.0</td>
      <td>12098328.0</td>
      <td>27689197.0</td>
      <td>73553203.0</td>
      <td>18022288.0</td>
      <td>18471915.0</td>
      <td>127918530.0</td>
    </tr>
    <tr>
      <th>2003-09-07 23:40:00</th>
      <td>8802106.0</td>
      <td>29932510.0</td>
      <td>5279285.0</td>
      <td>5950898.0</td>
      <td>20222187.0</td>
      <td>10636832.0</td>
      <td>19613671.0</td>
      <td>26124024.0</td>
      <td>8732768.0</td>
      <td>8217873.0</td>
      <td>...</td>
      <td>65087776.0</td>
      <td>28836922.0</td>
      <td>11075541.0</td>
      <td>52574692.0</td>
      <td>11933512.0</td>
      <td>31632344.0</td>
      <td>81693475.0</td>
      <td>16677568.0</td>
      <td>16766967.0</td>
      <td>138180630.0</td>
    </tr>
    <tr>
      <th>2003-09-07 23:50:00</th>
      <td>8716795.6</td>
      <td>22660870.0</td>
      <td>6240626.4</td>
      <td>5657380.6</td>
      <td>17406086.0</td>
      <td>8808588.5</td>
      <td>15962917.0</td>
      <td>18367639.0</td>
      <td>7767967.3</td>
      <td>7470650.1</td>
      <td>...</td>
      <td>65599891.0</td>
      <td>25862152.0</td>
      <td>11673804.0</td>
      <td>60086953.0</td>
      <td>11851656.0</td>
      <td>30979811.0</td>
      <td>73577193.0</td>
      <td>19167646.0</td>
      <td>19402758.0</td>
      <td>137288810.0</td>
    </tr>
  </tbody>
</table>
<p>1008 rows × 121 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Atraf</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1008, 121)
</pre></div>
</div>
</div>
</div>
<p>As we would expect, our traffic matrix has rank 121:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matrix_rank</span><span class="p">(</span><span class="n">Atraf</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>121
</pre></div>
</div>
</div>
</div>
<p>However – perhaps it has low <strong>effective</strong> rank.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">numpy</span></code> routine for computing SVD is <code class="docutils literal notranslate"><span class="pre">np.linalg.svd</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">u</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">vt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">Atraf</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s look at the singular values of <code class="docutils literal notranslate"><span class="pre">Atraf</span></code> to see if it can be usefully approximated as a low-rank matrix:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="p">)),</span><span class="n">s</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$k$&#39;</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\sigma_k$&#39;</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">ymin</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">xmin</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;Singular Values of $A$&#39;</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/10-Low-Rank-and-SVD_55_0.png" src="_images/10-Low-Rank-and-SVD_55_0.png" />
</div>
</div>
<p>This classic, sharp-elbow tells us that a few singular values are very large, and most singular values are quite small.</p>
<p>Zooming in for just small <span class="math notranslate nohighlight">\(k\)</span> values, we can see that the elbow is around 4 - 6 singular values:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">Anorm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">Atraf</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">21</span><span class="p">),</span> <span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">20</span><span class="p">]</span><span class="o">/</span><span class="n">Anorm</span><span class="p">,</span> <span class="s1">&#39;.-&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">20</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$k$&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">21</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\sigma_k$&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;Singular Values of $A$&#39;</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/10-Low-Rank-and-SVD_58_0.png" src="_images/10-Low-Rank-and-SVD_58_0.png" />
</div>
</div>
<p>This pattern of singular values suggests <strong>low effective rank.</strong></p>
<p>Let’s use the formula above to compute the relative error of a rank-<span class="math notranslate nohighlight">\(k\)</span> approximation to <span class="math notranslate nohighlight">\(A\)</span>:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">Anorm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">Atraf</span><span class="p">)</span>
<span class="n">err</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">s</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">err</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">err</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span> <span class="n">err</span><span class="p">[:</span><span class="mi">20</span><span class="p">]</span><span class="o">/</span><span class="n">Anorm</span><span class="p">,</span> <span class="s1">&#39;.-&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">21</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$k$&#39;</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;relative F-norm error&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;Relative Error of rank-$k$ approximation to $A$&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">16</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/10-Low-Rank-and-SVD_60_0.png" src="_images/10-Low-Rank-and-SVD_60_0.png" />
</div>
</div>
<p>Remarkably, we are down to 9% relative error using only a rank 20 approximation to <span class="math notranslate nohighlight">\(A\)</span>.</p>
<p>So instead of storing</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(mn =\)</span> (1008 <span class="math notranslate nohighlight">\(\cdot\)</span> 121) = 121,968 values,</p></li>
</ul>
<p>we only need to store</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(k(m+n)\)</span> = 20 <span class="math notranslate nohighlight">\(\cdot\)</span> (1008 + 121) = 22,580 values,</p></li>
</ul>
<p>which is a 81% reduction in size.</p>
</div>
<div class="section" id="low-effective-rank-is-common">
<h2>Low Effective Rank is Common<a class="headerlink" href="#low-effective-rank-is-common" title="Permalink to this headline">¶</a></h2>
<p>In practice <strong>many</strong> datasets have low effective rank.</p>
<p>Here are some more examples.</p>
<p><strong>Likes on Facebook.</strong></p>
<p>Here, the matrices are</p>
<ol class="simple">
<li><p>Number of likes:  Timebins <span class="math notranslate nohighlight">\(\times\)</span> Users</p></li>
<li><p>Number of likes:  Users <span class="math notranslate nohighlight">\(\times\)</span> Page Categories</p></li>
<li><p>Entropy of likes across categories:  Timebins <span class="math notranslate nohighlight">\(\times\)</span> Users</p></li>
</ol>
<center>
<img width=650, src = figs/L10-facebook.png/>
</center>
<p>Source: [Viswanath et al., Usenix Security, 2014]</p>
<p><strong>Social Media Activity.</strong></p>
<p>Here, the matrices are</p>
<ol class="simple">
<li><p>Number of Yelp reviews:  Timebins <span class="math notranslate nohighlight">\(\times\)</span> Users</p></li>
<li><p>Number of Yelp reviews:  Users <span class="math notranslate nohighlight">\(\times\)</span> Yelp Categories</p></li>
<li><p>Number of Tweets:  Users <span class="math notranslate nohighlight">\(\times\)</span> Topic Categories</p></li>
</ol>
<center>
<img width=650, src = figs/L10-yelp-twitter.png/>
</center>
<p>Source: [Viswanath et al., Usenix Security, 2014]</p>
<p><strong>User preferences over items.</strong></p>
<p>Example: the Netflix prize worked with partially-observed matrices like this:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\left[\begin{array}{ccccccc}
  ~&amp;~&amp;~&amp;\vdots&amp;~&amp;~&amp;~\\
  &amp;~&amp;3&amp;2&amp;~&amp;1&amp;\\
  &amp;1&amp;~&amp;1&amp;~&amp;~&amp;\\
  \dots&amp;~&amp;2&amp;~&amp;4&amp;~&amp;\dots\\
  &amp;5&amp;5&amp;~&amp;4&amp;~&amp;\\
  &amp;1&amp;~&amp;~&amp;1&amp;5&amp;\\
  ~&amp;~&amp;~&amp;\vdots&amp;~&amp;~&amp;~\\
\end{array}
\right]
\end{split}\]</div>
<p>Where the rows correspond to users, the columns to movies, and the entries are ratings.</p>
<p>Although the problem matrix was of size 500,000 <span class="math notranslate nohighlight">\(\times\)</span> 18,000, the winning approach modeled the matrix as having <strong>rank 20 to 40.</strong></p>
<p>Source: [Koren et al, IEEE Computer, 2009]</p>
<p><strong>Images.</strong></p>
<p>Image data often shows low effective rank.</p>
<p>For example, here is an original photo:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">boat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="s1">&#39;data/images/boat/boat.dat&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">matplotlib.cm</span> <span class="k">as</span> <span class="nn">cm</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">boat</span><span class="p">,</span><span class="n">cmap</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">Greys_r</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/10-Low-Rank-and-SVD_69_0.png" src="_images/10-Low-Rank-and-SVD_69_0.png" />
</div>
</div>
<p>Let’s look at its spectrum:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">u</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">vt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">boat</span><span class="p">,</span> <span class="n">full_matrices</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;$k$&#39;</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\sigma_k$&#39;</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Singular Values of Boat Image&#39;</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">16</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/10-Low-Rank-and-SVD_71_0.png" src="_images/10-Low-Rank-and-SVD_71_0.png" />
</div>
</div>
<p>This image is 512 <span class="math notranslate nohighlight">\(\times\)</span> 512.  As a matrix, it has rank of 512.</p>
<p>But its <em>effective</em> rank is low.</p>
<p>Based on the plot above, its effective rank is perhaps 40.</p>
<p>Let’s find the closest rank-40 matrix and view it.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">u</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">vt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">boat</span><span class="p">,</span> <span class="n">full_matrices</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
<span class="n">s</span><span class="p">[</span><span class="mi">40</span><span class="p">:]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">boatApprox</span> <span class="o">=</span> <span class="n">u</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="o">@</span> <span class="n">vt</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">boatApprox</span><span class="p">,</span><span class="n">cmap</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">Greys_r</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Rank 40 Boat&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">boat</span><span class="p">,</span><span class="n">cmap</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">Greys_r</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Rank 512 Boat&#39;</span><span class="p">);</span>
<span class="c1"># plt.subplots_adjust(wspace=0.5)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/10-Low-Rank-and-SVD_74_0.png" src="_images/10-Low-Rank-and-SVD_74_0.png" />
</div>
</div>
</div>
<div class="section" id="interpretations-of-low-effective-rank">
<h2>Interpretations of Low Effective Rank<a class="headerlink" href="#interpretations-of-low-effective-rank" title="Permalink to this headline">¶</a></h2>
<p>How can we understand the low-effective-rank phenomenon in general?</p>
<p>There are two helpful interpretations:</p>
<ol class="simple">
<li><p>Common Patterns</p></li>
<li><p>Latent Factors</p></li>
</ol>
<div class="section" id="low-rank-implies-common-patterns">
<h3>Low Rank Implies Common Patterns<a class="headerlink" href="#low-rank-implies-common-patterns" title="Permalink to this headline">¶</a></h3>
<p>The first interpretation of low-rank behavior is in answering the question:</p>
<p>“What is the strongest pattern in the data?”</p>
<p>Using the SVD we form the low-rank approximation as</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(U' = \)</span> the <span class="math notranslate nohighlight">\(k\)</span> leftmost columns of <span class="math notranslate nohighlight">\(U\)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\(\Sigma' = \)</span> the <span class="math notranslate nohighlight">\(k\times k\)</span> upper left submatrix of <span class="math notranslate nohighlight">\(\Sigma\)</span>, and</p></li>
<li><p><span class="math notranslate nohighlight">\(V'= \)</span> the <span class="math notranslate nohighlight">\(k\)</span> leftmost columns of <span class="math notranslate nohighlight">\(V\)</span>, and constructing</p></li>
</ul>
<p>with $<span class="math notranslate nohighlight">\( A \approx U'\Sigma'(V')^T \)</span>$</p>
<p>In this interpretation, we think of each column of <span class="math notranslate nohighlight">\(A\)</span> as a combination of the columns of <span class="math notranslate nohighlight">\(U'\)</span>.</p>
<p>How can this be helpful?</p>
<p>Consider the set of traffic traces.   There are clearly some common patterns.  How can we find them?</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;data/net-traffic/AbileneFlows/odnames&#39;</span><span class="p">,</span><span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">odnames</span> <span class="o">=</span> <span class="p">[</span><span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">]</span>
<span class="n">dates</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">date_range</span><span class="p">(</span><span class="s1">&#39;9/1/2003&#39;</span><span class="p">,</span><span class="n">freq</span><span class="o">=</span><span class="s1">&#39;10min&#39;</span><span class="p">,</span><span class="n">periods</span><span class="o">=</span><span class="mi">1008</span><span class="p">)</span>
<span class="n">Atraf</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="s1">&#39;data/net-traffic/AbileneFlows/X&#39;</span><span class="p">,</span><span class="n">sep</span><span class="o">=</span><span class="s1">&#39;  &#39;</span><span class="p">,</span><span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">names</span><span class="o">=</span><span class="n">odnames</span><span class="p">,</span><span class="n">engine</span><span class="o">=</span><span class="s1">&#39;python&#39;</span><span class="p">)</span>
<span class="n">Atraf</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">dates</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">13</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">i</span><span class="p">)</span>
    <span class="n">Atraf</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">odnames</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Twelve Example Traffic Traces&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">20</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/10-Low-Rank-and-SVD_81_0.png" src="_images/10-Low-Rank-and-SVD_81_0.png" />
</div>
</div>
<p>Let’s use as our example <span class="math notranslate nohighlight">\(\mathbf{a}_1,\)</span> the first column of <span class="math notranslate nohighlight">\(A\)</span>.</p>
<p>This happens to be the ATLA-CHIN flow.</p>
<p>The equation above tells us that</p>
<div class="math notranslate nohighlight">
\[\mathbf{a}_1 \approx v_{11}\sigma_1\mathbf{u}_1 + v_{12}\sigma_2\mathbf{u}_2 + \dots + v_{1k}\sigma_k\mathbf{u}_k.\]</div>
<p>In other words, <span class="math notranslate nohighlight">\(\mathbf{u}_1\)</span> (the first column of <span class="math notranslate nohighlight">\(U\)</span>) is the “strongest” pattern occurring in <span class="math notranslate nohighlight">\(A\)</span>, and its strength is measured by <span class="math notranslate nohighlight">\(\sigma_1\)</span>.</p>
<p>Here is an view of the first 2 columns of <span class="math notranslate nohighlight">\(U\Sigma\)</span> for the traffic matrix data.</p>
<p>These are the strongest patterns occurring across all of the 121 traces.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">u</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">vt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">Atraf</span><span class="p">,</span> <span class="n">full_matrices</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
<span class="n">uframe</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">u</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">s</span><span class="p">),</span> <span class="n">index</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">date_range</span><span class="p">(</span><span class="s1">&#39;9/1/2003&#39;</span><span class="p">,</span> <span class="n">freq</span> <span class="o">=</span> <span class="s1">&#39;10min&#39;</span><span class="p">,</span> <span class="n">periods</span> <span class="o">=</span> <span class="mi">1008</span><span class="p">))</span>
<span class="n">uframe</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">uframe</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;First Two Columns of $U$&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/10-Low-Rank-and-SVD_84_0.png" src="_images/10-Low-Rank-and-SVD_84_0.png" />
</div>
</div>
</div>
<div class="section" id="low-rank-defines-latent-factors">
<h3>Low Rank Defines Latent Factors<a class="headerlink" href="#low-rank-defines-latent-factors" title="Permalink to this headline">¶</a></h3>
<p>The next interpretation of low-rank behavior is that it exposes “latent factors” that describe the data.</p>
<p>Returning to the low-rank decomposition:</p>
<div class="math notranslate nohighlight">
\[ A \approx U'\Sigma'(V')^T \]</div>
<p>In this interpretation, we think of each element of <span class="math notranslate nohighlight">\(A\)</span> as the inner product of a row of <span class="math notranslate nohighlight">\(U'\Sigma'\)</span> and a row of <span class="math notranslate nohighlight">\(V'\)</span>.</p>
<p>Let’s say we are working with a matrix of users and items.</p>
<p>In particular, let the items be movies and matrix entries be ratings, as in the Netflix prize.</p>
<p>Recall the structure from a previous slide:</p>
<div class="math notranslate nohighlight">
\[\begin{split} \mbox{users}\left\{\begin{array}{c}\;\\\;\\\;\\\;\\\;\end{array}\right.\;\;\overbrace{\left[\begin{array}{cccc}\begin{array}{c}\vdots\\\vdots\\{\bf a_1}\\\vdots\\\vdots\end{array}&amp;\begin{array}{c}\vdots\\\vdots\\{\bf a_2}\\\vdots\\\vdots\end{array}&amp;\dots&amp;\begin{array}{c}\vdots\\\vdots\\{\bf a_n}\\\vdots\\\vdots\end{array}\\\end{array}\right]}^{\mbox{movies}} =
\overbrace{\left[\begin{array}{cc}\vdots&amp;\vdots\\\vdots&amp;\vdots\\\sigma_1\mathbf{u}_1&amp;\sigma_k\mathbf{u}_k\\\vdots&amp;\vdots\\\vdots&amp;\vdots\end{array}\right]}^{\large k}
\times
\left[\begin{array}{ccccc}\dots&amp;\dots&amp;\mathbf{v}_1&amp;\dots&amp;\dots\\\dots&amp;\dots&amp;\mathbf{v}_k&amp;\dots&amp;\dots\end{array}\right]\end{split}\]</div>
<p>Then the rating that a user gives a movie is the inner product of a <span class="math notranslate nohighlight">\(k\)</span> element vector that corresponds to the user, and a <span class="math notranslate nohighlight">\(k\)</span> element vector that corresponds to the movie.</p>
<p>In other words:</p>
<div class="math notranslate nohighlight">
\[ a_{ij} = \mathbf{u}_i^T \mathbf{v}_j\]</div>
<p>We can therefore think of user <span class="math notranslate nohighlight">\(i\)</span>’s preferences as being captured by <span class="math notranslate nohighlight">\(\mathbf{u}_i\)</span>, ie., a point in <span class="math notranslate nohighlight">\(\mathbb{R}^k\)</span>.</p>
<p>We have described everything we need to know to predict user <span class="math notranslate nohighlight">\(i\)</span>’s ratings via a <span class="math notranslate nohighlight">\(k\)</span>-element vector.</p>
<p>The <span class="math notranslate nohighlight">\(k\)</span>-element vector is called a <strong>latent factor.</strong></p>
<p>Likewise, we can think of <span class="math notranslate nohighlight">\(\mathbf{v}_j\)</span> as a “description” of movie <span class="math notranslate nohighlight">\(j\)</span> (another latent factor).</p>
<p>The value in using latent factors comes from the summarization of user preferences, and the predictive power one obtains.</p>
<p>For example, the winning entry in the Netflix prize competition modeled user preferences with a 20-element latent factor.</p>
<p>The remarkable thing is that a person’s preferences for all 18,000 movies can be reasonably well captured in a 20-element vector!</p>
<p>Here is a figure from the paper that described the winning strategy in the Netflix prize.</p>
<p>It shows a hypothetical <font color = 'blue'>latent space</font> in which each user, and each movie, is represented by a latent vector.</p>
<center>
<a class="reference internal image-reference" href="_images/L10-Movie-Latent-Space.png"><img alt="Figure" src="_images/L10-Movie-Latent-Space.png" style="width: 60%;" /></a>
</center>
<p>Source: Koren et al, IEEE Computer, 2009</p>
<p>In practice, this is perhaps a 20- or 40-dimensional space.</p>
<p>Here are some representations of movies in that space (reduced to 2-D).</p>
<p>Notice how the space seems to capture similarity among movies!</p>
<center>
<a class="reference internal image-reference" href="_images/L10-Netflix-Latent-Factors.png"><img alt="Figure" src="_images/L10-Netflix-Latent-Factors.png" style="width: 60%;" /></a>
</center>
<p>Source: Koren et al, IEEE Computer, 2009</p>
</div>
</div>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>When we are working with data matrices, it is valuable to consider the <strong>effective rank</strong></p></li>
<li><p>Many (many) datasets in real life show <strong>low effective rank</strong>.</p></li>
<li><p>This property can be explored precisely using the Singular Value Decomposition of the matrix.</p></li>
<li><p>When low effective rank is present,</p>
<ul>
<li><p>the matrix can be compressed with only small loss of accuracy</p></li>
<li><p>we can extract the “strongest” patterns in the data</p></li>
<li><p>we can describe each data item in terms of the inner product of <strong>latent factors.</strong></p></li>
</ul>
</li>
</ul>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="16-Classification-III-NB-SVM.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Naive Bayes and Support Vector Machines</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="11-Dimensionality-Reduction-SVD-II.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Dimensionality Reduction and PCA – SVD II</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Mark Crovella<br/>
    
        &copy; Copyright 2021-2022.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>